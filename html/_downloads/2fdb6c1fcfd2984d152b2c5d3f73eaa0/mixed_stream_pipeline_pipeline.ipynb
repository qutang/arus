{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDemonstration of the usage of arus.core.Pipeline (2)\n====================================================\n\nThe pipeline uses one annotation stream and one sensor stream as input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from arus.core.pipeline import Pipeline\nfrom arus.core.stream.generator_stream import GeneratorSlidingWindowStream\nfrom arus.core.accelerometer import generator as accel_generator\nfrom arus.core.annotation import generator as annot_generator\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\n\n\ndef _master_pipeline_processor(chunk_list, **kwargs):\n    import pandas as pd\n    import numpy as np\n    result = {'HEADER_TIME_STAMP': [], 'START_TIME': [],\n              'STOP_TIME': [], 'VALUE': [], 'ANNOTATION': []}\n    for data, st, et, prev_st, prev_et, name in chunk_list:\n        if len(result['START_TIME']) == 0 or result['START_TIME'][-1] != st:\n            result['HEADER_TIME_STAMP'].append(st)\n            result['START_TIME'].append(st)\n            result['STOP_TIME'].append(et)\n        if name == 'annotation-stream':\n            result['ANNOTATION'].append('-'.join(data.iloc[:, 3].values))\n        elif name == 'feature-pipeline':\n            result['VALUE'].append(data.iloc[0, 3])\n    result = pd.DataFrame.from_dict(result)\n\n    return result\n\n\ndef _feature_pipeline_processor(chunk_list, **kwargs):\n    import pandas as pd\n    import numpy as np\n    from arus.core.accelerometer.features import stats as accel_stats\n    from arus.core.accelerometer.transformation import vector_magnitude\n    result = {'HEADER_TIME_STAMP': [],\n              'START_TIME': [], 'STOP_TIME': [], 'VALUE': []}\n    for data, st, et, prev_st, prev_et, name in chunk_list:\n        result['HEADER_TIME_STAMP'].append(st)\n        result['START_TIME'].append(st)\n        result['STOP_TIME'].append(et)\n        vm_values = vector_magnitude(data.iloc[:, 1:].values)\n        values, name = accel_stats.mean(vm_values)\n        result['VALUE'].append(values[0, 0])\n    result = pd.DataFrame.from_dict(result)\n    return result\n\n\nif __name__ == \"__main__\":\n    # test on one annotation stream and one sensor stream + feature pipeline\n    stream1_config = {\n        \"generator\": accel_generator.normal_dist,\n        'kwargs': {\n            \"grange\": 8,\n            \"buffer_size\": 100,\n            \"sleep_interval\": 0,\n            \"sigma\": 1,\n            \"sr\": 80\n        }\n    }\n\n    stream2_config = {\n        \"generator\": annot_generator.normal_dist,\n        'kwargs': {\n            \"duration_mu\": 8,\n            \"duration_sigma\": 2,\n            \"sleep_interval\": 1,\n            \"num_mu\": 3,\n            \"labels\": [\"Sitting\", 'Standing', 'Lying', 'Walking', 'Running']\n        }\n    }\n\n    window_size = 12.8\n    sr = 80\n    start_time = datetime.now()\n    stream1 = GeneratorSlidingWindowStream(\n        stream1_config, window_size=window_size, start_time_col=0, stop_time_col=0, name='sensor-stream')\n    stream2 = GeneratorSlidingWindowStream(\n        stream2_config, window_size=window_size, start_time_col=1, stop_time_col=2, name='annotation-stream')\n\n    feat_pipeline = Pipeline(\n        max_processes=2, scheduler='processes', name='feature-pipeline')\n    feat_pipeline.add_stream(stream1)\n    feat_pipeline.set_processor(_feature_pipeline_processor)\n    master_pipeline = Pipeline(\n        max_processes=2, scheduler='processes', name='master-pipeline')\n    master_pipeline.add_stream(stream2)\n    master_pipeline.add_stream(feat_pipeline)\n    master_pipeline.set_processor(_master_pipeline_processor)\n    master_pipeline.start(start_time=start_time)\n    results = []\n    for result, st, et, prev_st, prev_et, name in master_pipeline.get_iterator():\n        results.append(result)\n        if len(results) == 10:\n            break\n        print(len(results))\n    print(master_pipeline.stop())\n    print(pd.concat(results, axis=0, sort=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}