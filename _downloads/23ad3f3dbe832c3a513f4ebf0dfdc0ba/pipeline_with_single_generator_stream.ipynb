{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPipeline with single sensor generator stream\n=====================================================================\n\nThis example demonstrates using pipeline with a single sensor generator stream.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n----------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nfrom datetime import datetime\n\nimport pandas as pd\nimport multiprocessing\n\nfrom arus.core.accelerometer import generator\nfrom arus.core.pipeline import Pipeline\nfrom arus.core.stream import GeneratorSlidingWindowStream\n\nmultiprocessing.freeze_support()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pipeline processor test function\n---------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _pipeline_test_processor(chunk_list, **kwargs):\n    import pandas as pd\n    result = {'NAME': [],\n              'START_TIME': [], 'STOP_TIME': []}\n    for data, st, et, prev_st, prev_et, name in chunk_list:\n        result['NAME'].append(name)\n        result['START_TIME'].append(data.iloc[0, 0])\n        result['STOP_TIME'].append(data.iloc[-1, 0])\n    result = pd.DataFrame.from_dict(result)\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Turn on logging info\n----------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(\n    level=logging.DEBUG, format='[%(levelname)s]%(asctime)s <P%(process)d-%(threadName)s> %(message)s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup sensor generator\n-----------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stream1_config = {\n    \"generator\": generator.normal_dist,\n    'kwargs': {\n        \"grange\": 8,\n        \"buffer_size\": 100,\n        \"sleep_interval\": 0,\n        \"sigma\": 1,\n        \"sr\": 80\n    }\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup stream\n--------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "window_size = 12.8\nstream1 = GeneratorSlidingWindowStream(stream1_config,\n                                       window_size=window_size,\n                                       start_time_col=0,\n                                       stop_time_col=0,\n                                       name='stream-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup pipeline\n----------------\nHere we use `threads` scheduler for demostration due to limitation of sphinx_gallery. In practice, you should better use `processes` scheduler to get benefit from multi-core processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(max_processes=1, scheduler='threads')\npipeline.add_stream(stream1)\npipeline.set_processor(_pipeline_test_processor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start pipeline and read in processed data\n-------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline.start()\nresults = []\nfor result, st, et, prev_st, prev_et, name in pipeline.get_iterator():\n    result['PREV_WINDOW_ST'] = prev_st\n    results.append(result)\n    if len(results) == 10:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stop pipeline\n----------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "success = pipeline.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output of the processed data\n------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output = pd.concat(results, axis=0, sort=False)\noutput"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}